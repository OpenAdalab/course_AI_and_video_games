{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Acceuil","text":""},{"location":"#cours-decouverte-de-lintelligence-artificielle-dans-les-jeux-videos","title":"Cours : D\u00e9couverte de l'Intelligence Artificielle dans les jeux vid\u00e9os","text":"<p>Bienvenue ! Vous trouverez sur ce site tous les supports du cours: le\u00e7ons, exercice et \u00e9valuations.</p> <p></p>  Auteur: Juan Martinez"},{"location":"#partage-diffusion-de-ce-cours","title":"Partage &amp; diffusion de ce cours","text":"<p>L'ensemble du contenu de ce site de cours est distribu\u00e9 sous licence Creative Commons CC-BY-NC-SA 4.0 (sauf dans les cas ou des licences plus restrictives s'appliquent)  Pensez \u00e0 respecter ces conditions d'utilisation et de diffusion (Attribution de l'auteur, utilisation non commerciale et partage dans les m\u00eames conditions) \ud83d\ude4f</p> <p>Nicolas Rochet - 2024 </p>"},{"location":"agents_intelligents/","title":"Les agents intelligents et leurs environnements","text":""},{"location":"agents_intelligents/#introduction","title":"Introduction","text":"<p>Le terme d'agent rationnel interagissant avec un environnement est un concept central de l'intelligence artificielle, puisqu'il est sous-jacent \u00e0 la plupart des concepts, th\u00e9ories et algorithmes que nous allons rencontrer dans cette discipline. On peut d\u00e9finir un agent comme une entit\u00e9 capable de percevoir son environnement par l'interm\u00e9diaire de capteurs sensoriels et d'agir sur cet environnement par l'interm\u00e9diaire d'effecteurs. </p> <p>Par exemple, un agent peut \u00eatre incarn\u00e9 par un humain, un robot ou encore un programme informatique, il per\u00e7oit son environnement sous forme de percepts en recevant des entr\u00e9es sensorielles (appuis claviers, contenu de fichiers, ...) et agissant sur son environnement (en affichant des informations sur un \u00e9cran, \u00e9crivant des fichiers, ...)</p>"},{"location":"agents_intelligents/#description-mathematique-et-implementation","title":"Description math\u00e9matique et impl\u00e9mentation","text":"<p>D'un point de vue math\u00e9matique, le comportement d'un agent est d\u00e9crit par une fonction d'agent , une description math\u00e9matique qui relie un percept donn\u00e9 \u00e0 une s\u00e9quence d'actions. On mod\u00e9lise souvent cette fonction d'agent sous forme de tableau, dans lequel, pour un environnement donn\u00e9, on r\u00e9f\u00e9rence la s\u00e9quence des percepts et les s\u00e9quences d'actions correspondantes. On distingue la fonction d'agent de son impl\u00e9mentation, le programme d'agent, qui op\u00e8re sur un syst\u00e8me physique (par exemple, un ordinateur) et est souvent repr\u00e9sent\u00e9e par le pseudo-code d'un algorithme.</p> <p>Illustrons ces notions par l'exemple dessin\u00e9 dans la figure 2.2 repr\u00e9sentant un agent d\u00e9fini par un aspirateur dans un environnement simple content deux localisations A, contenant de la poussi\u00e8re et B, vide. Dans cet environnement, l'agent peut effectuer les actions de bouger \u00e0 droite, \u00e0 gauche, aspirer la poussi\u00e8re, ou ne rien faire. Une des plus simples fonction d'agent que l'on puisse d\u00e9finir serait : \"Si l'endroit actuel est sale, alors aspire la poussi\u00e8re, sinon d\u00e9place toi vers l'autre localisation\". Une mod\u00e9lisation tabulaire partielle pour cette fonction est repr\u00e9sent\u00e9e par la figure 2.3.</p> <p>Figure 2.2: Exemple d'agent-aspirateur dans un environnement simple avec deux localisations. </p> S\u00e9quence de percepts Action [A, propre] Se d\u00e9placer \u00e0 droite [A, sale] Aspirer [B, propre] Se d\u00e9placer \u00e0 gauche [B, sale] Aspirer [A, propre], [A, propre] Se d\u00e9placer \u00e0 droite [A, propre], [A, sale] Aspirer ... ... <p>Figure 2.3: Mod\u00e9lisation partielle sous forme de tableau de notre agent-aspirateur </p> <p>Avec cette impl\u00e9mentation simple, on peut d\u00e9finir le comportement de notre agent en remplissant le tableau. La question \u00e9vidente qui se pose est de savoir comment remplir le tableau pour rendre notre agent intelligent ?</p>"},{"location":"agents_intelligents/#comportement-optimal-dun-agent-le-concept-de-rationalite","title":"Comportement optimal d'un agent: le concept de rationalit\u00e9","text":"<p>Intuitivement, un agent rationnel est un agent qui accomplit les bonnes actions. Dans notre exemple pr\u00e9c\u00e9dent construire un agent rationnel reviendrait \u00e0 pourvoir remplir la table de la figure 2.3 avec les meilleurs choix d'actions possibles pour chaque s\u00e9quence de percepts. Afin de d\u00e9finir plus pr\u00e9cis\u00e9ment le concept de rationalit\u00e9, on examine les cons\u00e9quences du comportement de l'agent sur son environnement: on recherche \u00e0 obtenir la s\u00e9quence d'\u00e9tats de l'environnement la plus d\u00e9sirable. Cette d\u00e9sirabilit\u00e9 est \u00e9valu\u00e9e par une mesure de la performance que l'agent rationnel cherchera \u00e0 maximiser par ses actions.</p> <p>Bien entendu, il n'y a typiquement pas de mesure de la performance id\u00e9ale pour toutes les t\u00e2ches et tous les agents, cela d\u00e9pendra des caract\u00e9ristiques du probl\u00e8me \u00e0 r\u00e9soudre. Par exemple, dans notre exemple pr\u00e9c\u00e9dent avec notre agent-aspirateur (figure 2.2), on pourrait proposer comme mesure de performance la quantit\u00e9 de poussi\u00e8re ramass\u00e9e par l'aspirateur pendant une p\u00e9riode donn\u00e9e. Un tel agent 'rationnel' pourrait maximiser cet mesure en nettoyant la poussi\u00e8re, puis la laisser tomber sur le sol pour la nettoyer de nouveau. Si le probl\u00e8me consiste \u00e0 simplement nettoyer l'environnement ce comportement ne parait pas optimal, une mesure plus appropri\u00e9e de la performance serait plut\u00f4t de r\u00e9compenser l'agent par un point \u00e0 chaque endroit qu'il a nettoy\u00e9 \u00e0 chaque pas de temps.</p>"},{"location":"agents_intelligents/#definition-de-la-rationalite-pour-un-agent","title":"D\u00e9finition de la rationalit\u00e9 pour un agent","text":"<p>Pour chaque s\u00e9quence de percepts possible, un agent rationnel est celui qui va s\u00e9lectionner l'action qui maximise la mesure de la performance attendue, ind\u00e9pendamment de la connaissance a priori que poss\u00e8de l'agent sur son environnement.</p> <p>Suivant cette d\u00e9finition, notre fonction d'agent d\u00e9finit plus t\u00f4t comme \"Si l'endroit actuel est sale, alors aspire la poussi\u00e8re, sinon d\u00e9place toi vers l'autre localisation\" caract\u00e9rise t'elle un agent rationnel ? Cela d\u00e9pend, il faut pour y r\u00e9pondre d\u00e9finir pr\u00e9cis\u00e9ment la mesure de la performance, la connaissance \u00e0 priori de l'agent de son environnement ainsi que ses percepts et actions possibles. Supposons que: - la performance consiste \u00e0 r\u00e9compenser d'un point chaque position nettoy\u00e9e \u00e0 chaque pas de temps durant une p\u00e9riode donn\u00e9e - la \"g\u00e9ographie\" de l'environnement est connue a priori mais la position initiale de la poussi\u00e8re et de l'aspirateur n'est pas forc\u00e9ment connue. - l'agent per\u00e7oit toujours correctement sa localisation et si celle-ci contient de la poussi\u00e8re. - dans l'environnement, \u00e0 chaque pas de temps, chaque case reste propre une fois qu'elle \u00e0 \u00e9t\u00e9 nettoy\u00e9e. - chaque nettoyage de l'aspirateur nettoie toujours la case dans laquelle il se trouve. - les actions \"se d\u00e9placer \u00e0 droite\" et \"se d\u00e9placer \u00e0 gauche\" d\u00e9placent toujours l'aspirateur sans qu'il sorte de son environnement. - les seules actions possibles sont \"se d\u00e9placer \u00e0 droite\", \"se d\u00e9placer \u00e0 gauche\" et \"nettoyer\".</p> <p>Alors, suivant ces circonstances, un tel agent est rationnel, sa performance sera toujours aussi \u00e9lev\u00e9e que celle de n'importe quel autre agent</p>"},{"location":"agents_intelligents/#non-omniscience-apprentissage-et-autonomie-des-consequences-de-notre-definition-de-la-rationalite","title":"Non-omniscience, apprentissage et autonomie: des cons\u00e9quences de notre d\u00e9finition de la rationalit\u00e9","text":"<ul> <li>Il est important de remarquer que notre d\u00e9finition de la rationalit\u00e9 ne requiert pas pour l'agent de poss\u00e9der une connaissance omnisciente des cons\u00e9quences de ses actions, qui est impossible dans la r\u00e9alit\u00e9. Ainsi, l'agent rationnel  cherche \u00e0 maximiser la performance attendue , qui d\u00e9pend uniquement de la s\u00e9quence de percepts connue au moment ou il agit.</li> <li>Notre d\u00e9finition implique qu'un agent rationnel soit capable, en g\u00e9n\u00e9ral,  de rassembler de l'information et d'apprendre autant que possible \u00e0 partir de ses percepts. Cet apprentissage lui permet de mettre a jour sa connaissance a priori de son environnement, except\u00e9 dans certains cas rare o\u00f9 son environnement est compl\u00e8tement connu a priori.</li> <li>Un agent rationnel devrait \u00eatre autonome, c'est \u00e0 dire que sa capacit\u00e9 \u00e0 apprendre lui permette de compenser une connaissance partielle ou incorrecte de son environnement.</li> </ul>"},{"location":"agents_intelligents/#proprietes-des-environnements-dune-tache","title":"Propri\u00e9t\u00e9s des environnements d'une t\u00e2che","text":"<p>On d\u00e9finit l'environnement d'une t\u00e2che (task environnement) comme l'ensemble englobant la performance d'un agent,  son environnement, ses effecteurs et ses capteurs sensoriels. Dans la discipline de l'Intelligence Artificielle, il est possible de cat\u00e9goriser un certain nombre d'environnements de t\u00e2ches en fonction de leur caract\u00e9ristiques:</p> <ul> <li> <p>L'environnement d'une t\u00e2che est partiellement versus totalement observable\u00a0si les capteurs peuvent percevoir une partie versus la totalit\u00e9 de l'\u00e9tat de l\u2019environnement \u00e0 chaque point de temps. Dans certains cas plus extr\u00eames, lorsque l'agent ne poss\u00e8de pas de capteurs, l'environnement est inobservable.</p> <p>Par exemple au poker, les cartes sont cach\u00e9es (ou partiellement observables) mais le fait de m\u00e9moriser les coups pass\u00e9s permet d\u2019acqu\u00e9rir des informations suppl\u00e9mentaires sur l\u2019environnement.</p> </li> <li> <p>L'environnement d'une t\u00e2che peut \u00eatre compos\u00e9 d'un agent simple versus un syst\u00e8me multi-agent, c'est \u00e0 dire un ensemble d'agents interagissant de mani\u00e8re comp\u00e9titive ou coop\u00e9rative dans un environnement pour accomplir une t\u00e2che donn\u00e9e.</p> </li> <li> <p>L'environnement d'une t\u00e2che est b\u00e9nin versus adverse\u00a0lorsque l\u2019environnement n\u2019a pas d\u2019objectif propre \u00e0 l'oppos\u00e9 d'un environnement qui essaye de contrecarrer les actions de l\u2019agent </p> <p>Par exemple, dans la plupart des sports ou dans certains jeux l\u2019adversaire est un environnement adverse.</p> </li> <li> <p>L'environnement d'une t\u00e2che est d\u00e9terministe versus stochastique\u00a0lorsque l'\u00e9tat futur de l'environnement est d\u00e9termin\u00e9 uniquement par le r\u00e9sultat des actions de l'agent on dit qu'il est d\u00e9terministe; dans tous les autres cas il est stochastique. Lorsque l'environnement d'une t\u00e2che n'est pas totalement observable ou pas d\u00e9terministe, on le qualifie d'incertain.</p> </li> <li> <p>L'environnement d'une t\u00e2che est \u00e9pisodique lorsque les exp\u00e9riences (percepts et action) de l'agent peuvent \u00eatre d\u00e9coup\u00e9es en \u00e9pisodes \u00e9l\u00e9mentaires. Dans chacun de ces \u00e9pisodes, l'agent re\u00e7oit un percept et ex\u00e9cute une action sans que cette action ne d\u00e9pende des exp\u00e9riences du pr\u00e9c\u00e9dent \u00e9pisodes. A l'oppos\u00e9 un environnement de t\u00e2che est s\u00e9quentiel, lorsque les exp\u00e9riences en cours peuvent affecter les actions futures de l'agent. </p> <p>Dans ce type d'environnement de t\u00e2ches assez courant, les actions \u00e0 court terme on des cons\u00e9quences \u00e0 long terme, ce qui conduit g\u00e9n\u00e9ralement les cr\u00e9ateurs d'agents \u00e0 lui impl\u00e9menter des strat\u00e9gies de planification \u00e0 long terme. La plupart des jeux de plateaux comme les \u00e9checs, sont des exemples d'environnements de t\u00e2ches s\u00e9quentiels </p> </li> <li> <p>L'environnement d'une t\u00e2che est dynamique si l'environnement auquel est confront\u00e9 l'agent peut changer pendant le temps ou l'agent prend une d\u00e9cision. Lorsque l'environnement ne change pas pendant le temps mais que la performance de l'agent change, on parle d'environnement semi-dynamique. Dans tous les autres cas on d\u00e9finit l'environnement de la t\u00e2che comme statique.</p> </li> <li> <p>L'environnement d'une t\u00e2che est discret versus continu\u00a0 lorsque l\u2019agent dispose d\u2019un nombre d\u00e9nombrable versus ind\u00e9nombrable de stimuli \u00e0 percevoir et d'actions \u00e0 ex\u00e9cuter.</p> </li> <li> <p>L'environnement d'une t\u00e2che est connu versus inconnu\u00a0en r\u00e9f\u00e9rence \u00e0 la connaissance que peut avoir l'agent (ou son cr\u00e9ateur) des lois qui gouvernent l'environnement (par exemple les lois de la physique). Dans un environnement connu, les cons\u00e9quences (ou leur probabilit\u00e9s) de toutes les actions sont connues. Dans un environnement inconnu l'agent devra apprendre \"comment l'environnement fonctionne\" pour prendre des bonnes d\u00e9cisions. </p> <p>Par exemple un environnement physique est connu car soumis au lois de la physique par opposition \u00e0 un environnement virtuel dans lequel son cr\u00e9ateur peut choisir les r\u00e8gles qui r\u00e9gissent cet environnement et les maintenir cach\u00e9es pour l'agent.</p> </li> </ul> <p>Comme vous pouvez vous en doutez, certains environnements de t\u00e2ches constituent des probl\u00e8mes plus compliqu\u00e9s \u00e0 r\u00e9soudre que d'autres, un des cas les plus durs \u00e9tant un environnement de t\u00e2che partiellement observable, multi-agent, stochastique, s\u00e9quentiel, dynamique continu, adverse et inconnu.</p>"},{"location":"agents_intelligents/#differents-types-dagents","title":"Diff\u00e9rents types d'agents","text":"<p>De mani\u00e8re g\u00e9n\u00e9rale en Intelligence Artificielle, on estime que les principes d\u00e9finissant la plupart des syst\u00e8mes intelligents s'incarnent en quatre grandes cat\u00e9gories d'agents. Chacun d'entre eux combine des composants particulier pour prendre des d\u00e9cisions et g\u00e9n\u00e9rer des actions.  </p> <ul> <li> <p>les simple-reflex agents: ce type d'agent r\u00e9pondent directement aux percepts qu'ils re\u00e7oit en se basant sur des r\u00e8gles condition-action pr\u00e9 d\u00e9termin\u00e9es.</p> <p>Par exemple pour un agent de conduite autonome, une r\u00e8gle simple de condiction-action peut \u00eatre \"si le v\u00e9hicule qui est situ\u00e9 devant freine alors freine.</p> </li> <li> <p>les model-based reflex agents: ce type agent poss\u00e8de un mod\u00e8le de l'environnement (de simple r\u00e8gles logiques \u00e0 de complexes th\u00e9ories scientifiques) qui leur permette de maintenir une trace de l'\u00e9tat interne de l'environnement \u00e0 un instant t pour mettre \u00e0 jour sa repr\u00e9sentation de l'environnement et en cons\u00e9quence ex\u00e9cuter des actions plus performantes. Ce genre d'agent est environnement est particuli\u00e8rement adapt\u00e9 dans les environnements partiellement observables.</p> <p>Par exemple, notre agent de conduite autonome doit pouvoir d\u00e9tecter, \u00e0 un instant t, sur le v\u00e9hicule le pr\u00e9c\u00e9dant les lumi\u00e8res rouges indiquant un appui sur le frein et stocker cette information , pour pouvoir mettre a jour sa repr\u00e9sentation de l'environnement \u00e0 un instant t+1 et \"d\u00e9cider\" de freiner.</p> </li> <li> <p>les goal-based agents: ce type d'agent poss\u00e8de les m\u00eame composants que les model-based reflex agents avec un composant suppl\u00e9mentaire, un but qui lui permette de d\u00e9cider si une situation est \"d\u00e9sirable\" pour choisir une action \u00e0 effectuer. G\u00e9n\u00e9ralement les comportement de ce type d'agents sont plus flexible que ceux des deux types pr\u00e9c\u00e9dents en contrepartie de performances parfois moins importantes.</p> </li> <li> <p>les utility-based agents:  ce type d'agents int\u00e8grent, en plus des autres composants pr\u00e9sents chez les autres types d'agents, une fonction d'utilit\u00e9 qui agit comme une mesure de la performance, interne \u00e0 l'agent . Si cette mesure interne s'accorde avec la mesure externe de la performance, alors un agent qui maximise sa fonction d'utilit\u00e9 adoptera un comportement rationnel (puisqu'il maximisera aussi la performance externe).</p> </li> </ul> <p>Pour plus de d\u00e9tails concernant la construction et le fonctionnement de ces agents r\u00e9f\u00e9rez vous au chapitre 2.4 du livre cit\u00e9 en source.</p>"},{"location":"agents_intelligents/#lexique-du-chapitre","title":"Lexique du chapitre","text":""},{"location":"agents_intelligents/#termes-generaux","title":"Termes g\u00e9n\u00e9raux","text":"<ul> <li>Un algorithme est une suite finie et non ambigu\u00eb d\u2019op\u00e9rations ou d'instructions permettant de r\u00e9soudre une classe de probl\u00e8mes.</li> <li>Le pseudo-code est une fa\u00e7on de d\u00e9crire un algorithme en langage presque naturel, sans r\u00e9f\u00e9rence \u00e0 un langage de programmation en particulier. </li> </ul>"},{"location":"agents_intelligents/#les-agents","title":"Les agents","text":"<ul> <li>Un percept d\u00e9signe l'ensemble des entr\u00e9e sensorielles re\u00e7ues par un agent. Une s\u00e9quence de percepts d\u00e9signe l'historique complet de tous les percepts de l'agent.</li> </ul>"},{"location":"agents_intelligents/#sources","title":"Sources","text":"<p>Chapitre 2 du livre Artificial Intelligence, A modern approach, 3\u00e8me \u00e9dtition. Sutart Russel &amp; Peter Norwig, Pearson. </p>"},{"location":"decouverte_IA/","title":"Chapitre 1: D\u00e9couverte de l'IA","text":""},{"location":"decouverte_IA/#lecon-decouverte-de-lintelligence-artificielle","title":"Le\u00e7on: D\u00e9couverte de l'Intelligence Artificielle","text":"<p>Commen\u00e7ons par un tour d'horizon ludique pour d\u00e9couvrir l'IA et ses r\u00e9cents progr\u00e8s avec le machine learning dans les deux derni\u00e8res d\u00e9cennies</p>"},{"location":"installation_python_simple/","title":"Installation et gestion du langage python et de ses librairies","text":""},{"location":"installation_python_simple/#installation-de-vos-composants-pour-python","title":"Installation de vos composants pour python","text":"<p>Dans ce cours, vous allez utiliser des  gestionnaires de paquets et environnements virtuels et y installer python et ses principaux packages pour la data science.    </p> <p>R\u00e9f\u00e9rez vous \u00e0 la le\u00e7on sur la gestion de paquets en python pour plus de d\u00e9tails</p> <p>Installez une version de python &gt;= 3.10</p> Utilisez la distribution miniconda <p>Vous pouvez installer python par de nombreux moyen, mais je vous conseille d'utiliser le gestionnaire de paquets et d'environnements virtuels miniconda afin de vous faciliter la gestion des paquets en python.</p>"},{"location":"installation_python_simple/#via-miniconda","title":"Via miniconda","text":"<p>Suivez la documentation d'installation officielle de miniconda. Installez la version la plus r\u00e9cente de la distribution miniconda, dans laquelle python et quelques paquets essentiels seront pr\u00e9-install\u00e9</p>"},{"location":"installation_python_simple/#installation-de-modules-python","title":"Installation de modules python","text":"<p>Si vous avez install\u00e9 python via anaconda ou miniconda, la plupart des modules qui nous seront n\u00e9cessaires devraient d\u00e9ja \u00eatre install\u00e9s. </p> <p>Sinon vous pouvez les installer facilement en utilisant, au choix <code>pip</code> (l'installateur officiel de paquets en python) ou <code>conda</code>: <pre><code>pip install &lt;package_name&gt; \nconda install &lt;package_name&gt;\n</code></pre></p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/","title":"R\u00e9solution de problemes appliqu\u00e9e au jeux","text":""},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#comment-definir-un-probleme","title":"Comment d\u00e9finir un probl\u00e8me ?","text":"<p>La r\u00e9solution de probl\u00e8me fait partie historiquement d'un des grand domaines de l'Intelligence Artificielle. Dans ce domaine, de nombreux probl\u00e8mes qui se rapportent \u00e0 un environnement d\u00e9terministe, observable, statique et compl\u00e9tement connu, peuvent \u00eatre r\u00e9solu par des agents capables de trouver des solutions \u00e0 ces probl\u00e8mes en construisant des sequences d'actions r\u00e9pondant \u00e0 un but (les goal-based agents). </p> <p>Math\u00e9matiquement, ces probl\u00e8mes se caract\u00e9risent par six propri\u00e9t\u00e9s: - une repr\u00e9sentation de l'environnement par un espace des \u00e9tats - un \u00e9tat initial s avec lequel l'agent d\u00e9marre. - une description de toutes les actions possibles par l'agent qui se mod\u00e9lise par une fonction \\(Actions(s) \u27f6 {a_1,a_2, a_3, ...}\\)  - une description des r\u00e9sultats de chacune de ces actions qui se mod\u00e9lise par une fonction qui renvoie un nouvel \u00e9tat s', r\u00e9sultat de l'action a effectu\u00e9e dans l'\u00e9tat s: \\(Resultats(s, a) \u27f6 s'\\)  - une fonction de but interne \u00e0 l'agent qui lui permet de d\u00e9cider si l'\u00e9tat en cours s correspond \u00e0 un \u00e9tat \u00e0 atteindre.  - une solution au probl\u00e8me, d\u00e9finie comme un chemin \u00e0 travers l'espace des \u00e9tats entre l'\u00e9tat initial et le but.  - une fonction de cout qui d\u00e9temine une valeur num\u00e9rique pour chaque chemin dans l'environnement.  </p> <p>Les algorithmes de recherche de graphe sont une classe de solutions tr\u00e8s populaire pour ce genre de probl\u00e8me; certains de ces algorithmes ont permis de r\u00e9aliser des progr\u00e8s important dans la recherche en Intelligence Artificielle depuis ses d\u00e9buts \u00e0 nos jours, notamment dans les jeux.</p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#les-jeux-en-tant-que-problemes","title":"Les jeux en tant que probl\u00e8mes","text":"<p>Dans l'Intelligence Artificielle, les jeux int\u00e9ressent beaucoup les chercheurs car ils appartiennent \u00e0 une cat\u00e9gorie de probl\u00e8mes difficile \u00e0 r\u00e9soudre, contrairement \u00e0 des probl\u00e8mes plus simple pour lequel on connait des algorithmes offrant une solution optimale, comme par exemple, le probl\u00e8me du plus court chemin.</p> <p>Ainsi les probl\u00e8mes associ\u00e9s au jeux poss\u00e8dent des contraintes additionnelles du fait de la pr\u00e9sence d'un ou plusieurs adversaires: - les solutions et leur optimalit\u00e9 d\u00e9pendent des caract\u00e9ristiques des adversaires. - les agents doivent souvent trouver des r\u00e9ponses dans un temps limit\u00e9, ce qui exige parfois la recherche de solution approximative. - la cr\u00e9ation d'une bonne fonction d'\u00e9valuation des \u00e9tats de l'environnement (ou ici, les situations de jeu) est d\u00e9licate et d\u00e9pend fortement des propri\u00e9t\u00e9s du jeu.</p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#caracterisation-de-notre-environnement-de-tache-pour-le-projet-pac-man","title":"Caract\u00e9risation de notre environnement de t\u00e2che pour le projet Pac Man","text":"<p>Dans notre projet Pac Man multi agent, il est imp\u00e9ratif de d\u00e9finir notre environnement de t\u00e2che afin de pouvoir mod\u00e9liser notre probl\u00e8me et d'en chercher des solutions. L'environnement de t\u00e2che du jeu est:</p> <ul> <li>totalement obervable: Pac Man conna\u00eet la totalit\u00e9 de l'environnement du jeu (voir dans le code l'objet <code>GameState</code>).  </li> <li>multi-agent: vous devrez mod\u00e9liser le comportement de Pac Man en prenant en compte celui des fant\u00f4mes.  </li> <li>adverse: les fant\u00f4mes cherchent \u00e0 \u00e9liminer Pac Man.  </li> <li>d\u00e9terministe: les actions de Pac Man ne sont influenc\u00e9es par aucune variable al\u00e9atoire.  </li> <li>s\u00e9quentiel: vous avez plut\u00f4t int\u00e9r\u00eat \u00e0 consid\u00e9rer que l'\u00e9tat du jeu \u00e0 un instant t-1 puisse influencer les actions de Pac Man \u00e0 l'\u00e9tat \u00e0 l'instant t.   </li> <li>discret: les actions possibles de Pac Man sont d\u00e9nombrables.  </li> <li>connu: vous avez plut\u00f4t int\u00e9r\u00eat \u00e0 donner \u00e0 Pac Man la connaissance \u00e0 priori des r\u00e8gles qui r\u00e9gissent son environnement.  </li> </ul>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#parcours-de-graphes-arbres-le-contexte-des-jeux","title":"Parcours de graphes &amp; arbres :  le contexte des jeux","text":"<p>Si vous n'\u00eates pas familier avec la notion de graphes, vous en avez s\u00fbrement d\u00e9ja utilis\u00e9 sans le savoir. Par exemple, si vous avez d\u00e9ja utilis\u00e9 un GPS pour vous rendre d'un point A \u00e0 un point B, vous avez exp\u00e9riment\u00e9 une classe d'algorithmes d\u00e9di\u00e9e \u00e0 r\u00e9soudre le probl\u00e8me du plus court chemin, algorithmes qui fonctionnent en visitant un graphe repr\u00e9sentant la carte de votre voyage.</p> <p>De la m\u00eame mani\u00e8re que le probl\u00e8me du plus court chemin peut se mod\u00e9liser sous forme de graphe et en particulier sous forme d'arbre (une sous cat\u00e9gorie de graphe), la plupart des jeux se pr\u00eatent bien \u00e0 cette mod\u00e9lisation. Dans ce type de mod\u00e9lisation, qu'on appelle alors d'arbre de jeu, les noeuds repr\u00e9sentent des \u00e9tat de l'environnement (ici des situations de jeu) et les arr\u00eates les mouvements possibles des joueurs.</p> <p>Dans certains jeux simples comme le tic-tac-toe (qui ne poss\u00e8de que 362 880 noeuds terminaux), l'arbre de jeu peut mod\u00e9liser compl\u00e8tement l'ensemble des \u00e9tats possibles jusqu'aux \u00e9tats terminaux qui repr\u00e9sentent les \u00e9tats de fin de partie et dont la valeur est \u00e9valu\u00e9e par la fonction d'utilit\u00e9.  </p> <p> Figure 3.1: Exemple d'arbre (partiel) de jeu pour le tic-tac-toe. Le noeud racine correspond \u00e0 l'\u00e9tat initial de la partie, puis les coups du joueur MAX sont repr\u00e9sent\u00e9s pas les X et ceux du joueurs MIN par les O. Les noeuds terminaux repr\u00e9sentent les \u00e9tats finaux possible de la partie, qui sont \u00e9valu\u00e9s par une fonction d'utilit\u00e9.   </p> <p>Cependant la plupart des jeux sont trop complexes pour qu'on puisse les repr\u00e9senter compl\u00e9tement par un arbre, c'est le cas par exemple des \u00e9checs dont l'arbre de jeu serait constitu\u00e9 de \\(10^{40}\\) noeuds !  Dans ce genre de cas, on utilise alors des arbres de recherche qui repr\u00e9sentent uniquement un nombre suffisant d'\u00e9tats pour permettre \u00e0 notre agent de choisir le coup \u00e0 jouer.  Suivant cette mod\u00e9lisation, on peut utiliser des m\u00e9thodes de parcours de graphe pour trouver la solution au probl\u00e8me du jeu, \u00e0 savoir d\u00e9terminer le meilleur coup \u00e0 jouer.</p> <p>Dans le cas de notre projet Pac Man , le choix des actions de Pac Man peuvent se mod\u00e9liser par un arbre de recherche, c'est le premier ingr\u00e9dient pour notre agent rationnel.</p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#fonction-dutilite-et-fonction-devaluation","title":"Fonction d'utilit\u00e9 et fonction d'\u00e9valuation","text":"<p>Le second ingr\u00e9dient pour mod\u00e9liser le comportement d'un agent rationnel comme notre Pac Man consiste \u00e0 pouvoir \u00e9valuer l'utilit\u00e9 des situations de jeu \u00e0 chaque instant.  Le concept de fonction d'utilit\u00e9 vient des domaines de la th\u00e9orie de la d\u00e9cision et de l'\u00e9conomie. Transpos\u00e9e au domaine de l'Intelligence Artificielle, la fonction d'utilit\u00e9 sert \u00e0 estimer une valeur pour les \u00e9tats terminaux d'un environnement, par exemple, dans le cas d'un jeu, en assignant la valeur +1 pour le gain et la valeur -1 pour une perte de la partie. Cette fonction permet aux agents de d\u00e9cider de leurs actions en cherchant \u00e0 maximiser leur fonction d'utilit\u00e9, il s'agit des utility-based agents vus au chapitre sur les agents intelligents.</p> <p>Dans un jeu simple pour lequel on pourrait mod\u00e9liser et calculer toutes les situations de jeu dans un temps acceptable, la fonction d'utilit\u00e9 seule pourrait suffire \u00e0 d\u00e9duire, en partant des \u00e9tats terminaux, les valeurs des situations de jeu interm\u00e9diaires, mais ce cas est tr\u00e8s rare dans la pratique. Dans la plupart des jeux, nous aurons besoin d'estimer la valeur des situations de jeu interm\u00e9diaires, en \u00e9valuant la possibilit\u00e9 que ces situations puissent conduire \u00e0 la victoire d'un joueur donn\u00e9. On utilise pour ce faire une fonction d'\u00e9valuation qui est souvent difficile \u00e0 mod\u00e9liser. La mod\u00e9lisation de cette fonction n\u00e9cessite souvent des connaissances sur le jeu et n'est pas souvent garantie d'\u00eatre optimale, c'est pourquoi on ne se contente souvent d'utiliser une heuristique de fonction d'\u00e9valuation.</p> <p>Par exemple, aux \u00e9checs on attribue des valeurs \u00e0 chaque pi\u00e8ce en fonction de sa puissance. Une heuristique de fonction d'\u00e9valuation souvent utilis\u00e9e consiste \u00e0 calculer la diff\u00e9rence de la valeur des pi\u00e8ces captur\u00e9es par chacun des joueurs. </p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#algorithme-minimax","title":"Algorithme minimax","text":""},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#definition-et-premiere-intuition","title":"D\u00e9finition et premi\u00e8re intuition","text":"<p>L'algorithme minimax est un algorithme r\u00e9cursif de parcours de graphe utilis\u00e9 dans les jeux \u00e0 n joueurs pour choisir les actions que doit effectuer un joueur (ou un agent artificiel). Il permet de calculer la valeur pour chaque \u00e9tat s de l'environnement \u00e0 partir d'une heurisitique de  fonction d'\u00e9valuation qui permet d'approximer l'utilit\u00e9 de l'\u00e9tat s (savoir s'il s'agit d'une bonne ou mauvais actions \u00e0 jouer). Cet algorithme est souvent utilis\u00e9 en particulier dans les jeux \u00e0 somme nulle, un sous domaine de la th\u00e9orie des jeux. Dans ce type de jeux, correspondant \u00e0 environnement de t\u00e2che adverse, la probl\u00e9matique r\u00e9side dans le fait que chaque joueur va chercher \u00e0 maximiser la valeur \u00e9tat s de l'environnement . Dans un jeu de plateau comme les \u00e9checs par exemple, il faut prendre en compte dans le choix des coups le fait que l'adversaire cherche \u00e9galement \u00e0 maximiser son coup, il est alors simpliste de se contenter de simplement choisir le \"meilleur coup dans l'absolu\".  </p> <p>Intuitivement, l'algorithme minimax r\u00e9pond \u00e0 ce probl\u00e8me en proposant une r\u00e8gle de d\u00e9cision qui vise \u00e0 minimiser la possible perte maximale (correspondant au pire des scenarii possible pour notre agent). Il calcule la valeur minimax pour notre agent, c'est \u00e0 dire la valeur minimale de l'\u00e9tat s que les autres joueurs peuvent engendrer, sans conna\u00eetre leur actions.</p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#description","title":"Description","text":"<p>Dans cette description nous supposerons, pour simplifier, que deux joueurs sont adversaires, le joueur A (qui correspond \u00e0 l'agent que l'on souhaite mod\u00e9liser) et son adversaire, le joueur B. Notez bien que ce joueur fonctionne avec n joueurs/agents, ce qui correspond \u00e0 votre cas pour la mod\u00e9lisation de vos agents dans le projet Pac Man (Pac Man &amp; les fant\u00f4mes). G\u00e9n\u00e9ralement, lorsque l'on d\u00e9crit cet algorithme, on d\u00e9signe le joueur A comme le joueur maximisant et son adversaire, le joueur B, comme le joueur minimisant. </p> <p>Dans la plupart des jeux, il est souvent irr\u00e9aliste de pouvoir mod\u00e9liser tous les \u00e9tats du jeu jusqu'aux \u00e9tats terminaux car le temps d'\u00e9xecution de l'algorithme minimax serait trop important. Dans la pratique, on souhaite appliquer minimax sur un arbre suffisamment profond pour que sa performance soit importante, tout en conservant un temps d'\u00e9xecution acceptable. Cet arbre est d'autant plus profond que l'on mod\u00e9lise de futurs tours de jeu par joueurs, les plies. La figure 3.2 ci-dessous repr\u00e9sente un exemple d'arbre de recherche simpliste dans lequel sont repr\u00e9sent\u00e9s uniquement 3 \u00e9tats du jeu.</p> <p> Figure 3.2: Exemple simpliste d'un arbre repr\u00e9sentant trois tours de jeu dans un jeu \u00e0 somme nulle avec deux joueurs. Chaque noeud repr\u00e9sente la valeur estim\u00e9e de la situation de jeu pour notre agent, le joueur A (rectangles gris) et son adversaire, le joueur B (ronds bleu). </p> <p>Voyons maintenant les \u00e9tapes du processus de fonctionnement de l'algorithme Minimax. Celui-ci fonctionne de mani\u00e8re r\u00e9cursive et ascendante:   </p> \\[ Minimax(s) = \\left\\{     \\begin{array}{ll}         utilit\u00e9(s) &amp; si~noeud = noeud~terminal \\\\         max_{a\\in Actions(s)}~Minimax(Result(s,a)) &amp; si~Joueur(s) = MAX\\\\         min_{a\\in Actions(s)}~Minimax(Result(s,a)) &amp; si~Joueur(s) = MIN\\\\     \\end{array} \\right. \\] <ul> <li> <p>On part des noeuds terminaux de l'arbre auquel on attribue une valeur d'utilit\u00e9 par une heuristique de fonction d'\u00e9valuation. Ensuite, on remonte l'arbre et on \u00e9value les noeuds pr\u00e9c\u00e9dents successivement jusqu'au noeud racine (qui correspond \u00e0 l'\u00e9tat actuel du jeu).</p> </li> <li> <p>Si les noeuds correspondent \u00e0 ceux de l'adversaire, c'est \u00e0 dire le joueur minimisant (ronds bleus), on calcule leur valeurs pour chacun d'eux en minimisant le minimax de chacun des ses noeuds fils. Intuitivement, on cherche \u00e0 s\u00e9lectionner le minimum de la pire situation de jeu que pourrait jouer notre agent (joueur A) en r\u00e9ponse au coup du joueur B.  </p> </li> <li> <p>Si les noeuds correspondent \u00e0 ceux de notre agent, c'est \u00e0 dire le joueur maximisant (rectangle gris), on calcule leur valeurs pour chacun d'eux en maximisant le minimax de chacun des ses noeuds fils. Intuitivement, on cherche \u00e0 s\u00e9lectionner le maximum de la pire situation de jeu que pourrait provoquer l'adversaire (joueur B) en r\u00e9ponse au coup de notre agent.</p> </li> </ul> <p>L'algorithme s'arr\u00eate lorsque l'on est remont\u00e9 jusqu'au noeud racine qui est \u00e9valu\u00e9 par l'heuristique de la fonction d'\u00e9valuation. En g\u00e9n\u00e9ral, la qualit\u00e9 de l'estimation de la valeur des noeuds terminaux et la profondeur de l'arbre d\u00e9termine la qualit\u00e9 du r\u00e9sultat final (le prochain mouvement \u00e0 jouer).</p> <p>Pour plus de d\u00e9tails interactifs concernant le fonctionnement de Minimax, vous pouvez visionner cette bonne vid\u00e9o.</p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#limitations-de-minimax-ameliorations-possibles","title":"Limitations de minimax &amp; am\u00e9liorations possibles","text":"<p>Dans la plupart des jeux, le nombre de situations de jeu possible est tr\u00e8s grand, comme c'est le cas par exemple au \u00e9checs et encore plus au go. De plus, le parcours de l'abre par l'algorithme minimax, le nombre de noeuds \u00e0 explorer  augmente exponentiellement avec le nombre de tours de jeu (plies), ce qui tend \u00e0 rendre l'algorithme incalculable dans un temps acceptable. C'est pourquoi dans la pratique, on limite tr\u00e8s souvent la profondeur de l'arbre \u00e0 une dizaine de tours de jeu. A titre d'exemple, le minimax utilis\u00e9 par Deep Blue dans sa victoire contre Kasparov au \u00e9chec avait une profondeur de 12 tours de jeu.</p> <p>En g\u00e9n\u00e9ral, une des mani\u00e8res les plus r\u00e9pandues de r\u00e9duire temps de calcul d'algorithme de parcours d'arbres consiste \u00e0 \"\u00e9lager\", certaines branches de l'arbre qui ne seront ainsi pas visit\u00e9es. En particulier dans le cas de l'algorithme minimax, il existe un algorithme d'\u00e9lagage, l'algorithme d'\u00e9lagage alpha-beta qui donne les m\u00eames r\u00e9sultats que l'algorithme minimax \"naif\" mais sans visiter certaines branches qui n'influenceraient pas la d\u00e9cision finale.</p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#elagage-alpha-beta","title":"Elagage alpha-beta","text":""},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#principe-general","title":"Principe g\u00e9n\u00e9ral","text":"<p>Tout comme minimax, il s'agit d'un algorithme de parcours de graphe en profondeur : \u00e0 chaque noeud, il n'explore d'abord des fils. Appliqu\u00e9 a minimax, il permet ainsi de parourir le graphe en profondeur tout en \u00e9lagant certaines branches \u00e0 ne pas visiter en fonction de deux valeurs \u03b1 *** et \u03b2***. Il \u00e0 l'avantage de donner les m\u00eame r\u00e9sultats qu'aurait donn\u00e9 minimax seul, mais avec un temps d'\u00e9xecution moindre.</p> <p>Tout au long du parours du graphe, l'algorithme calcule les valeurs  \u03b1 et \u03b2 d\u00e9finies comme suivant: - \u03b1 =  plus grande valeur que l'on peut garantir jusqu'ici (dans la branche en cours de visite)  pour le joueur maximisant - \u03b2 =  plus petite valeur que l'on peut garantir jusqu'ici (dans la branche en cours de visite)  pour le joueur minimisant </p> <p>L'algorithme s'\u00e9x\u00e9cute comme suit : 1. Initialisation des valeurs telles qu'elle correspondent au pire score possible pour chaque joueur (\u03b1 *** =  -\u221e et \u03b2 *** = +\u221e) 2. on met \u00e0 jour les valeurs \u03b1 et  \u03b2 au fur et \u00e0 mesure de la visite de l'arbre et on \u00e9limine les noeuds (et leur branches associ\u00e9es) ayant des valeurs v telles que  \u03b1 \u2a7e v et  \u03b2 \u2a7d v.</p> <p> Figure 3.3: Exemple d'application de l'\u00e9lagage alpha-beta.</p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#jeux-stochastiques","title":"Jeux stochastiques","text":"<p>Jusqu'a pr\u00e9sent nous avons \u00e9voqu\u00e9 uniquement des jeux purement d\u00e9terministes, dans lesquels aucun \u00e9l\u00e9ment de l'environnement de t\u00e2che n'est d\u00e9pendant du hasard. Dans beaucoup de situations de la vie r\u00e9elle certains \u00e9v\u00e9nements sont impr\u00e9dictibles. Certains jeux imitent ce caract\u00e8re impr\u00e9dicitble, en incluant pas exemple des \u00e9lements al\u00e9atoires comme des lanc\u00e9s de d\u00e9s, on parle alors de jeux stochastiques.  Dans ce type de jeux, les d\u00e9cisions de notre agent vont donc reposer sur des ph\u00e9nom\u00e8nes al\u00e9atoires qu'il faut mod\u00e9liser.</p> <p>Le backgammon est un bon exemple de jeu en partie stochastique puisqu'il n\u00e9cessite de combiner des talents de prise de d\u00e9cision et une partie de chance. Le but du jeu pour chaque joueur consiste \u00e0 d\u00e9placer des pions sur un plateau et de r\u00e9ussir \u00e0 tous les sortir du plateau. L'\u00e9l\u00e9ment al\u00e9atoire provient du fait qu'\u00e0 chaque tour chaque joueur lance des d\u00e9s qui indiqueront les coups possibles \u00e0 effectuer pour ce joueur et ce tour. Ainsi lorsque le 1er joueur commence \u00e0 jouer, il ne connait pas encore les coups l\u00e9gaux pour son adversaire, qui seront d\u00e9termin\u00e9s par un lanc\u00e9 de d\u00e9. Cette contrainte pose un probl\u00e8me de mod\u00e9lisation des situations de jeu, car nous ne pouvons plus utiliser ici un arbre de jeu simple comme nous l'avons vu pr\u00e9c\u00e9demment pour le tic-tac-toe ou les \u00e9checs. </p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#expectiminimax","title":"Expectiminimax","text":"<p>Cet algorithme est une variation de l'algorithme minimax deont principe g\u00e9n\u00e9ral consiste \u00e0 \u00e9tendre l'arbre utilis\u00e9 dans l'algorithme minimax en y ajoutant un nouveau type de noeuds, les noeuds chance qui vont servir \u00e0 mod\u00e9liser les \u00e9lements al\u00e9atoires du jeu. On construit alors un nouveau type d'arbre en alternant des noeuds de type min, max et chance.</p> <p>L'algorithme fonctionne de mani\u00e8re similaire \u00e0 celui de minimax pour le calcul des valeurs des noeuds terminaux et des noeuds min et max. Par contre, pour estimer la valeur de chaque noeud chance on calcule sa valeur attendue qui correspond \u00e0 la somme des valeurs de ses noeuds fils du ph\u00e9nom\u00e8ne, pond\u00e9r\u00e9 par leur probabilit\u00e9 d'apparition. Math\u00e9matiquement, on calcule donc la valeur du noeud chance n par la formule:  </p> <p>Avec C l'ensemble des noeuds fils c du noeud courant n, \\(P_c\\), la probabilit\u00e9 d'occurence de l'\u00e9venement repr\u00e9sent\u00e9 par le noeud c,  \\(V_c\\) la valeur courante du noeud c (r\u00e9sultat de l'application r\u00e9cursive de la fonction expectiminimax sur les noeuds fils de c)   Le pseudo-code de l'algorithme est donn\u00e9e dans la partie Annexes</p> <p>Pour reprendre l'exemple du backgammon, les joueurs lancent deux d\u00e9s pour d\u00e9terminer les coups l\u00e9gaux. Au noeud chance n, la somme des valeur \\(V_c\\) est pond\u00e9r\u00e9e par les probabilit\u00e9s d'occurence des d\u00e9s: \\(\\frac{1}{36}\\) pour les faces identiques et \\(\\frac{1}{18}\\) pour les autres combinaisons.</p> <p> Figure 3.4: Exemple d'application de l'algorithme expectiminimax.</p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#application-aux-jeux-multi-joueurs","title":"Application aux jeux multi joueurs","text":"<p>Attention, dans les exemples pr\u00e9sent\u00e9s ci-dessus, nous avons repr\u00e9sent\u00e9, par souci de simplicit\u00e9, des jeux \u00e0 somme nulle \u00e0 deux joueurs. Les algorithmes de parcours de graphes que nous avons \u00e9voqu\u00e9 plus haut s'appliquent \u00e9galement dans un contexte de jeux multi joueur. C'est dailleurs le cas dans l'environnement de t\u00e2che de notre jeu Pac Man: il va falloir que vous mod\u00e9lisiez les actions des plusieurs ennemis sur l'\u00e9tat du jeu.  Un piste pour adapter les exemples vus plus haut va consister \u00e0 ajouter dans vos algorithmes de recherche de graphe d'autres joueurs, les fant\u00f4mes. De plus vous devrez adapter la fonction d'\u00e9valuation pour qu'elle renvoie, \u00e0 chaque noeud un n-uplet (tuple) de valeurs plut\u00f4t qu'une valeur unique.</p> <p> Figure 3.5: Exemple d'application de l'algorithme minimax avec 3 joueurs A, B et C.</p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#quelques-pistes-de-recherches-pour-votre-projet","title":"Quelques pistes de recherches pour votre projet","text":"<ul> <li>Faire varier le nombre de tour de jeux (plies) \u00e0 prendre en compte dans votre arbre.</li> <li>Faire varier la fonction d'\u00e9valuation utliser.</li> <li>Tester les variantes de l'algorithme minimax: l'\u00e9lagage alpha-beta et expectiminimax </li> <li>Utiliser des heuristiques particuli\u00e8res pour mod\u00e9liser des buts. <p>Par exemple, il pourra\u00eet \u00eatre int\u00e9ressant de tester une strat\u00e9gie audacieuse dans laquelle Pac Man chercherait \u00e0 s'orienter vers les boules lui permettant de manger les fant\u00f4mes (ce qui accorde plus de points) en utilisant des algorithmes de recherche du plus court chemin, ou au contraire strat\u00e9gie prudente dans laquelle Pac Man chercherait \u00e0 rester le plus loin possible des fant\u00f4mes, ce qui pourrait \u00eatre utile dans les cas ou les fant\u00f4mes sont lanc\u00e9 en mode aggressif.</p> </li> <li>Aller explorer d'autres algorithmes plus sophistiqu\u00e9s comme Iterative deepening, SSS*, Max\\(^n\\) search, Monte carlo tree search</li> </ul>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#lexique-du-chapitre","title":"Lexique du chapitre","text":""},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#vocabulaire-de-la-theorie-des-graphes","title":"Vocabulaire de la th\u00e9orie des graphes","text":"<ul> <li>Un graphe est un objet math\u00e9matique de la th\u00e9orie des graphes compos\u00e9 de noeuds, repr\u00e9sentant une valeur et de relations entre eux, les ar\u00eates.</li> <li>Un arbre\u00a0est un cas particulier de graphe non orient\u00e9, acyclique et connexe. Il poss\u00e8de des n\u0153uds particuliers qu\u2019on appelle racine (le n\u0153ud qui n\u2019a pas de parents) et feuilles (n\u0153uds qui n\u2019ont aucun enfant).</li> <li>Un graphe orient\u00e9 est un graphe dans lequel les noeuds sont associ\u00e9 suivant une direction indiquant le sens de parcours du graphe, repr\u00e9sent\u00e9e par une fl\u00e8che.</li> <li>Contrairement au graphe orient\u00e9, le graphe non orient\u00e9 ne poss\u00e8de pas de direction d\u00e9finissant son sens de parcours.</li> <li>Un un graphe non orient\u00e9 G = (S,A) est dit connexe si, quels que soient les sommets u et v de S, il existe une cha\u00eene reliant u \u00e0 v</li> <li>Une branche est ensemble fini de noeuds et d'arr\u00eates (connexes) constituant un sous-graphe.</li> <li>Un arbre enracin\u00e9 est un graphe acyclique orient\u00e9 poss\u00e9dant une racine unique et dans lequel tous les noeuds sauf la racine poss\u00e8dent un unique parent. </li> <li>Un algorithme de parcours de graphe est un type d'algorithme consistant \u00e0 visiter les noeuds d'un graphe. Il existe plusieurs strat\u00e9gies diff\u00e9rentes de parcours de graphe comme le parcours en profondeur ou le parcours en largeur.</li> </ul>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#vocabulaire-de-la-theorie-des-jeux","title":"Vocabulaire de la th\u00e9orie des jeux","text":"<ul> <li>Un jeu \u00e0 somme nulle est un jeu dans lequel la somme des gains et des pertes de tous les joueurs est \u00e9gale \u00e0 0. Cela signifie donc que le gain de l'un constitue obligatoirement une perte pour l'autre.  Par exemple si l'on d\u00e9finit le gain d'une partie d'\u00e9checs comme 1 si on gagne, 0 si la partie est nulle et -1 si on perd, le jeu d'\u00e9checs est un jeu \u00e0 somme nulle. </li> <li>Dans un jeu s\u00e9quentiel \u00e0 2 joueur, un ply est un tour jou\u00e9 par un des deux joueurs.</li> </ul>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#vocabulaire-de-linformatique-et-de-lalgorithmie","title":"Vocabulaire de l'informatique et de l'algorithmie","text":"<ul> <li>Dans le domaine de la r\u00e9solution de probl\u00e8me, une heuristique correspond \u00e0 une solution pratique \u00e0 un probl\u00e8me, qui n'est pas garantie d'\u00eatre optimale ou rationnelle mais qui est suffisante pour atteindre rapidement un objectif \u00e0 court terme. Lorsque l'on ne conna\u00eet pas de solution optimale \u00e0 un probl\u00e8me ou que celle-ci est incalculable, alors les m\u00e9thodes heuristiques servent souvent am\u00e9liorer le temps de calcul pour une solution satisfaisante. <p>Par exemple, A*, un algorithme utilis\u00e9 dans le probl\u00e8me de la recherche du plus court chemin utilise une heuristique souvent choisie comme la distance \u00e0 vol d'oiseau entre la point de d\u00e9part et la destination. Gr\u00e2ce \u00e0 l'usage de cette heuristique il est plus rapide que son concurrent qui offre une solution optimale, l'algorithme de Dijkstra.</p> </li> <li>Un arbre de recherche (search tree) est une structure de donn\u00e9e utils\u00e9e pour localiser des neouds ayant des valeurs sp\u00e9cifiques dans un arbre enracin\u00e9 (au sens de la th\u00e9orie des graphe). Attention \u00e0 ne pas confondre avec la notion de tree search qui correspond \u00e0 la classe d'algorithme de parcours de graphe.</li> </ul>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#annexes","title":"Annexes:","text":""},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#pseudo-code-des-possibles-implementations","title":"Pseudo-code des possibles impl\u00e9mentations","text":""},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#algorithme-minimax_1","title":"Algorithme minimax","text":"<pre><code>function minimax(node, depth, maximizingPlayer) is\nif depth = 0 or node is a terminal node then\n    return the heuristic value of node\nif maximizingPlayer then\n    value := \u2212\u221e\n    for each child of node do\n        value := max(value, minimax(child, depth \u2212 1, FALSE))\n    return value\nelse (* minimizing player *)\n    value := +\u221e\n    for each child of node do\n        value := min(value, minimax(child, depth \u2212 1, TRUE))\n    return value\n\n(* Initial call *)\nminimax(origin, depth, TRUE)\n</code></pre>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#elagage","title":"Elagage \u03b1\u03b2","text":"<pre><code>function alphabeta(node, depth, \u03b1, \u03b2, maximizingPlayer) is\nif depth = 0 or node is a terminal node then\n    return the heuristic value of node\nif maximizingPlayer then\n    value := \u2212\u221e\n    for each child of node do\n        value := max(value, alphabeta(child, depth \u2212 1, \u03b1, \u03b2, FALSE))\n        \u03b1 := max(\u03b1, value)\n        if \u03b1 \u2265 \u03b2 then\n            break (* \u03b2 cut-off *)\n    return value\nelse\n    value := +\u221e\n    for each child of node do\n        value := min(value, alphabeta(child, depth \u2212 1, \u03b1, \u03b2, TRUE))\n        \u03b2 := min(\u03b2, value)\n        if \u03b1 \u2265 \u03b2 then\n            break (* \u03b1 cut-off *)\nreturn value\n\n(* Initial call *)\nalphabeta(origin, depth, \u2212\u221e, +\u221e, TRUE)\n</code></pre> <p>\u200b        </p>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#expectiminimax_1","title":"Expectiminimax","text":"<pre><code>function expectiminimax(node, depth)\nif node is a terminal node or depth = 0\n    return the heuristic value of node\nif the adversary is to play at node\n    // Return value of minimum-valued child node\n    let value := +\u221e\n    foreach child of node\n        value := min(value, expectiminimax(child, depth-1))\nelse if we are to play at node\n    // Return value of maximum-valued child node\n    let value := -\u221e\n    foreach child of node\n        value := max(value, expectiminimax(child, depth-1))\nelse if random event at node\n    // Return weighted average of all child nodes' values\n    let value := 0\n    foreach child of node\n        value := value + (Probability[child] * expectiminimax(child, depth-1))\nreturn value\n\n(* Initial call *)\nexpectiminimax(origin, depth)\n</code></pre>"},{"location":"resolution_problemes_appliqu%C3%A9e_au_jeux/#sources","title":"Sources","text":"<ul> <li>Page  wikipedia pour l'algorithme Minimax</li> <li>Page wikipedia pour l'algorithme d'\u00e9lagage alpha-beta</li> <li>Page wikipedia pour l'algorithme expectiminimax</li> <li>Chapitres 3 \u00e0 5 du livre Artificial Intelligence, A modern approach, 3\u00e8me \u00e9dtition. Sutart Russel &amp; Peter Norwig, Pearson.</li> <li>Th\u00e8se de J,A,M Nijssen, Monte-Carlo tree search for multiplayer games</li> <li>Chapitre 5 du cours Adevrsarial search and game playing, Olivier schulte</li> </ul>"},{"location":"tour_horizon_IA_%26_JV/","title":"Tour d'horizon : l'IA dans les jeux vid\u00e9os","text":""},{"location":"tour_horizon_IA_%26_JV/#programme","title":"Programme","text":"<p>Dans ce chapitre nous allons d\u00e9couvrir :</p> <ul> <li>les diff\u00e9rents types d'IA et d'algorithmes et leur cas d'applications dans les jeux vid\u00e9os</li> <li>des exemples d'algorithmes  utilis\u00e9s en fonction des types de jeux</li> </ul>"},{"location":"tour_horizon_IA_%26_JV/#lecon-tour-dhorizons-des-ia-dans-les-jeux-videos","title":"Le\u00e7on : tour d'horizons des IA dans les jeux vid\u00e9os","text":""},{"location":"evaluations/Projet1_multiagent_pacman/","title":"Projet 1: R\u00e9alisation d'un pac-man multi agent","text":""},{"location":"evaluations/Projet1_multiagent_pacman/#description-du-projet","title":"Description du projet","text":"<p>Dans ce projet votre d\u00e9fi va consister \u00e0 impl\u00e9menter diff\u00e9rents agents (de plus en plus intelligents) incarnant pac-man dans sa version classique. La description du projet d\u00e9taill\u00e9e est accessible dans ce module de cours de Standford. </p>"},{"location":"evaluations/Projet1_multiagent_pacman/#notions-theoriques-necessaires","title":"Notions th\u00e9oriques n\u00e9cessaires","text":"<p>Pour travailler sur ce projet vous aurez besoin de conna\u00eetre les notions ci dessous. Si nous vous n'avons pas eu encore l'occasion de voir en d\u00e9tail certaines d'entre elles vous pouvez d\u00e9ja commencer \u00e0 les appr\u00e9hender en faisant vos propres recherches !</p> <ul> <li>les notions de graphes et d'arbres</li> <li>les algorithmes de recherche du plus court chemin</li> <li>les algorithmes minimax et sa variation Expectiminimax utilis\u00e9s dans la th\u00e9orie des jeux et l'IA comme r\u00e8gle de d\u00e9cision.</li> <li>l'algorithme d'\u00e9lagage alpha-beta qui vous permettra de r\u00e9duire le nombre de noeuds \u00e9valu\u00e9s lors du parcours de graphe</li> <li>la notion de fonction d'\u00e9valuation</li> </ul>"},{"location":"evaluations/Projet1_multiagent_pacman/#environnement-necessaire","title":"Environnement n\u00e9cessaire","text":"<p>Au cours de ce projet vous aurez besoin de programmer votre agent pacman en python 3.</p> Si vous n'avez pas install\u00e9 python <p>Si vous n'avez pas install\u00e9 python sur votre machine, r\u00e9f\u00e9rez vous \u00e0     la section Pr\u00e9-requis de ce cours, en installant un environnement virtuel d\u00e9di\u00e9 pour ce projet. Notez que vous n'aurez pas besoin pour ce projet de packages suppl\u00e9mentaires \u00e0 python.</p>"},{"location":"evaluations/Projet1_multiagent_pacman/#code-du-projet","title":"Code du projet","text":"<p>Clonez ce d\u00e9pot git  pour installer le code python n\u00e9cessaire au projet: <pre><code>git clone git@github.com:HerySon/course_pacman_project.git\n</code></pre> Le code contient diff\u00e9rents modules permettant d'afficher le labyrinthe, de renvoyer chaque \u00e9tat de la partie, les actions des agents ainsi que leur intelligence artificielle. Vous n'aurez besoin de modifier dans le code que les parties concernant leur IA en impl\u00e9mentant dans le module <code>multiAgentsSolution</code> \u00e0 minima la classe <code>MinimaxAgent</code> ainsi que les classes <code>AlphaBetaAgent</code> et <code>ExpectimaxAgent</code> si elle vous paraissent pertinentes pour mod\u00e9liser votre agent.</p>"},{"location":"evaluations/Projet1_multiagent_pacman/#implementer-le-code-de-mon-agent-en-python","title":"Impl\u00e9menter le code de mon agent en python","text":"Si vous n'\u00eates pas familier avec python <p>Si vous n'\u00eates pas familier avec python, ca n'est pas tr\u00e8s grave: les concepts pr\u00e9sent\u00e9s dans le cours ne d\u00e9pendent pas d'un langage particulier. Vous trouverez de nombreuses ressources en ligne ainsi que dans la section Ressources additionnelles de ce cours.  </p> <p>L'algorithme minimax et ses variantes \u00e9tant des sujets bien trait\u00e9s, vous trouverez facilement du code sur internet pour vous aider. N'h\u00e9sitez pas \u00e0 vous en servir, mais surtout en essayant de bien comprendre et tester le code que vous trouverez : je vous invite en particulier \u00e0 examiner les valeurs attribu\u00e9es aux noeuds de votre graphe lors du calcul du minimax !</p>"},{"location":"evaluations/Projet1_multiagent_pacman/#vous-etre-maintenant-pret-a-commencer-a-programmer-vos-agents","title":"Vous \u00eatre maintenant pr\u00eat \u00e0 commencer \u00e0 programmer vos agents !","text":""},{"location":"ressources%20additionnelles/elements_cours/","title":"Ressources pour aller plus loin","text":"<p>Dans cette page vous trouverez des ressources (\u00e9l\u00e9ments de cours,  chapitres, cours en ligne, vid\u00e9os, ...) que j'ai collect\u00e9 et rassembl\u00e9e  pour faciliter votre auto-apprentissage.</p>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/","title":"Pour continuer votre formation","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#data-science","title":"Data Science","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#programmation-en-python","title":"Programmation en python","text":"<p>Pour trouver des ressources pertinentes en fonction de votre exp\u00e9rience en python, r\u00e9f\u00e9rez vous au Chapitre 2 du cours Data Science</p>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#programmation-orientee-objet-en-python","title":"Programmation orient\u00e9e objet en python","text":"<p>Si vous souhaitez approfondir vos connaissances sur la programmation orient\u00e9 objet en python, vous pouvez suivre ces cours d'Open Classrooms, en fonction de votre besoin:</p> <ul> <li>cous niveau facile</li> <li>cours niveau moyen</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#mini-cours","title":"Mini cours","text":"<p>R\u00e9cemment la plateforme kaggle \u00e0 mise en place des mini cours accompagn\u00e9s d'exercices corrig\u00e9s par chapitres qui sont rapides \u00e0 faire. Ces cours vous permettront de d\u00e9couvrir certaines notions fondamentales, que vous aurez l'occasion de creuser par la suite.</p> <p>Je vous conseille, en fonction de votre niveau de connaissance, et par ordre de priorit\u00e9 de suivre les mini cours suivants:</p> <ul> <li>l'apprentissage de pandas le module de python le plus utilis\u00e9 pour g\u00e9rer les donn\u00e9es tabulaires</li> <li>l'introduction aux bases du langage SQL pour la manipulation de base de donn\u00e9es. Optionnellement, vous pouvez allez plus loin, en explorant des fonctionnalit\u00e9s plus avanc\u00e9es du langage SQL, notamment en apprenant \u00e0 combiner plusieurs tables</li> <li>apprendre les principes de base du nettoyage de donn\u00e9es et pourrez compl\u00e9ter vos connaissances en testant des m\u00e9thodes d'apprentissage automatique pour le pr\u00e9-traitement de donn\u00e9es en explorant le menu d\u00e9di\u00e9 du framework sckit-learn. Pour aller encore plus loin, vous pouvez tester les algorithmes d'apprentissage semi-supervis\u00e9 pour la labellisation automatique de donn\u00e9e du m\u00eame framework</li> <li>enfin vous pouvez terminer votre apprentissage des principes de bases en \u00e9tudiant le feature engineering</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#elements-de-cours-par-thematique","title":"El\u00e9ments de cours par th\u00e9matique","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#algorithmie","title":"Algorithmie","text":"<p>Vous pourrez d\u00e9couvrir des bases pratiques de l'algorthmie avec ce cours d'Open Classroom. Je vous conseille de cibler en particulier les chapitres concernant les structure de donn\u00e9es files, listes et arbres</p>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#cours-francophones-complets","title":"Cours francophones complets","text":"<p>Les cours suivants sont des cours tr\u00e8s complet qui sont dispens\u00e9s dans des masters sp\u00e9cialis\u00e9s dans la data science. Vous n'aurez probablement pas le temps de les explorer compl\u00e8tement, je vous conseille de vous y r\u00e9f\u00e9rer uniquement quand vous avez besoin d'approfondir un sujet pr\u00e9cis ou pour rechercher des exercices suppl\u00e9mentaires</p> <ul> <li>le cours  du master SISE de Lyon 2  consacr\u00e9 \u00e0 la data science et au data mining, en particulier les cours de mise \u00e0 niveau, que je conseille particuli\u00e8rement si vous avez fait peu de maths et d'informatique (en particulier du python)</li> <li>le cours du module de data science du cours de l'ENSAE \u00e0 Paris</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#mathematiques-pour-la-data-science-et-le-machine-learning","title":"Math\u00e9matiques pour la data science et le machine learning","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#livres","title":"Livres","text":"<ul> <li>Afin d'approfondir en continu votre apprentissage des math\u00e9matiques de bases pour la data science et le machine learning, n'h\u00e9sitez pas \u00e0 fouiller parmi les chap\u00eetres du livre mathematics for machine learning lorsque vous aurez besoin d'approfondir  certaines notions fondamentales ou d'en d\u00e9couvrir d'autres.</li> <li>An introduction to statistical learning est un ouvrage de r\u00e9f\u00e9rence, quasiement la bible de la data science et du machine learning ! Je vous conseille de le consulter lorsque vous aurez d\u00e9ja un niveau de base en data science et machine learning et que vous aurez besoin de vous plonger dans les math\u00e9matiques d\u00e9taill\u00e9es d'un concept particulier</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#cours-videos","title":"Cours &amp; vid\u00e9os","text":"<p>Je vous invite \u00e0 continuer \u00e0 vous former tout au long du cours, au fur et a mesure que vous aurez besoin d'approfondir certaines notions.</p> <ul> <li>Vous trouverez sur cet article de blog de toward data science une liste tr\u00e8s compl\u00e8te de ressources pour acqu\u00e9rir les fondamentaux de maths pour la data science</li> <li>Pour explorer certains sujets pr\u00e9cis, vous pouvez lire cette serie d'articles th\u00e9matiques par Hadrien Jean (tir\u00e9 de son livre)</li> <li>Enfin, si vous d\u00e9butez et souhaiter apprendre les math\u00e9matiques depuis un niveau coll\u00e8ge, je vous conseille les cours de la plateforme khan academy (vous trouverez beaucoup de contenus en fran\u00e7ais)</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#algebre-lineaire","title":"Alg\u00e8bre lin\u00e9aire","text":"<p>L'alg\u00e8bre lin\u00e9aire est un domaine des math\u00e9matiques dont vous aurez particuli\u00e8rement besoin durant ce cours pour comprendre les notions de vecteurs, matrices, tenseurs et leurs op\u00e9rations associ\u00e9es.</p> <ul> <li> <p>Je vous conseille de regarder l'int\u00e9gralit\u00e9 de la s\u00e9rie de vid\u00e9os Essence of linear algebra, de l'excellente cha\u00eene de vulgarisation math\u00e9matique 3Blue1Brown </p> </li> <li> <p>En fran\u00e7ais, je vous conseille la s\u00e9rie de cours vid\u00e9o de khan academy : </p> </li> <li> <p>introduction \u00e0 l'alg\u00e8bre lin\u00e9aire</p> </li> <li>les vecteurs &amp; espaces vectoriels</li> <li>les matrices d'applications lin\u00e9aires</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#analyse-fonctionnelle-et-calul","title":"Analyse fonctionnelle et calul","text":"<p>Je vous conseille de regarder l'int\u00e9gralit\u00e9 de la s\u00e9rie de vid\u00e9os Essence of calculus, de l'excellente cha\u00eene de vulgarisation math\u00e9matique 3Blue1Brown</p>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#machine-learning","title":"Machine Learning","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#introduction-au-machine-learning","title":"Introduction au Machine Learning","text":"<ul> <li> <p>Je vous recommande de lire la page tutoriel de scikit-learn qui vous introduit quelques bases du machine learning accompagn\u00e9es d'exemples qui vous permettront d'apprendre \u00e0 programmer avec ce framework indispensable.</p> </li> <li> <p>La page des ressources \u00e9ducatives du framework tensorflow propose plein de livres et de cours (dont la plupart sont gratuits) que vous pouvez explorer pour d\u00e9velopper vos connaissances th\u00e9oriques et techniques sur le machine learning et le deep learning.</p> </li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#cours-complets","title":"Cours complets","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#anglophones","title":"Anglophones","text":"<ul> <li>La plateforme Kaggle propose maintenant des cours accompagn\u00e9s d'exercices concernant le machine learning, Intro to Machine Learning  et Intermediate Machine Learning que je vous conseille de faire si possible en int\u00e9gralit\u00e9.</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#francophones","title":"Francophones","text":"<ul> <li>La plateforme Open Classrooms propose deux cours assez complets que vous pouvez suivre en s\u00e9lectionnant les chapitres qui compl\u00e9teront le plus vos connaissances : perfectionnez vos bases avec le cours Initiez vous au machine learning et avec approfondissez les notions d'\u00e9valuation vos algorithmes en \u00e9vitant le biais de sur apprentissage cours Evaluez les performances d'un mod\u00e8le de machine learning </li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#par-thematique","title":"Par th\u00e9matique","text":"<ul> <li>Un article du blog towards data science vulgaris\u00e9 sur les param\u00e8tres et hyper-param\u00e8tres des r\u00e9seaux de neurones</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#deep-learning","title":"Deep Learning","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#ressources-generalistes","title":"Ressources g\u00e9n\u00e9ralistes","text":"<p>La page des ressources \u00e9ducatives du framework tensorflow propose un contenu tr\u00e8s riche contenant livres, cours en ligne, concepts math\u00e9matiques, ressources tensorflow, ...  Je vous conseille vivement de vous y r\u00e9f\u00e9rez pour d\u00e9velopper vos connaissances th\u00e9oriques et techniques (pour le machine learning et le deep learning) et vous aider pour la r\u00e9alisation des projets.</p> <p>Bien que les cours francophones propos\u00e9s soient de bonne qualit\u00e9, je vous conseille de suivre les cours en anglais, car ils sont g\u00e9n\u00e9ralement plus nombreux et  plus complets.</p>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#livres_1","title":"Livres","text":"<p>Deep learning, par Ian Goodfellow, Yoshua Bengio and Aaron Courville, est un livre de r\u00e9f\u00e9rence pour un apprentissage complet des bases th\u00e9oriques du deep learning</p>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#elements-de-cours-en-ligne","title":"El\u00e9ments de cours en ligne","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#anglophones_1","title":"Anglophones","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#gratuits","title":"Gratuits","text":"<ul> <li> <p>Les vid\u00e9os de d\u00e9couverte des reseaux de neurones de Hugo Larochelle vous permettent de d\u00e9couvrir en 92 courtes pr\u00e9sentations (exc\u00e9dant rarement les 15 minutes) des points cl\u00e9s pour compl\u00e9ter votre compr\u00e9hension de certains sujets</p> </li> <li> <p>Le cours offrant le meilleur compromis exhaustivit\u00e9/temps que je vous conseille de regarder en priorit\u00e9 et en int\u00e9gralit\u00e9 (il dure moins d'une heure), est ce cours r\u00e9cent d'introduction au Deep Learning par le MIT</p> </li> <li>Ce cours Standford est un des meilleur et des plus complet sur le sujet. Vous pouvez retrouverez les vid\u00e9os des cours magistraux ici</li> <li>Le cours fast.ai est un tr\u00e8s bon cours, destin\u00e9 aux programmeurs pour apprendre l'essentiel de la technique et de la th\u00e9orie rapidement. Concentrez vous en particulier sur la le\u00e7on 1.</li> <li>Ce cours de Michael Nielsen extrait de son livre, est tr\u00e8s illustr\u00e9 et vous permettra de peaufiner certains points particuliers</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#payants","title":"Payants","text":"<ul> <li>Ce cours de Andrew Ng, un des pionniers du deep learning est disponible sur la plateforme Coursera</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#francophones_1","title":"Francophones","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#gratuits_1","title":"Gratuits","text":"<ul> <li> <p>Les cours de la plateforme Fidle (co-cr\u00e9e) par le CNRS est un cours en francais les plus complets : il reprend les conceptes fondamentaux en cours vid\u00e9o et est mis \u00e0 jour r\u00e9guli\u00e8rement avec les derni\u00e8res avanc\u00e9es</p> </li> <li> <p>Le cours d'OpenClassroom, Initiez vous au deep learning. Le cours du CNAM couvre assez rapidement les principes g\u00e9n\u00e9raux. Les diapositives du cours sont en anglais.</p> </li> <li> <p>Pour ceux qui ne connaissent pas le machine learning, vous pouvez suivre ce cours d'initiation d'OpenClassroom</p> </li> <li> <p>Vous trouverez des fiches de cours de bonne qualit\u00e9, pr\u00e9cises et d\u00e9taill\u00e9es, sur des points sp\u00e9cifiques ( comme la descente de gradient, le perceptron) sur le cours du Master SISE de Lyon</p> </li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#payants_1","title":"Payants","text":"<ul> <li>La plateforme Udemy \u00e0 ouvert un cours sur le deep learning, c'est probablement le plus complet en fran\u00e7ais \u00e0 l'heure actuelle.</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#etat-de-lart","title":"Etat de l'art","text":"<p>Je vous conseille l'excellent site papers with code qui r\u00e9f\u00e9rence une bonne partie de l'\u00e9tat de l'art, par t\u00e2ches, en proposant des articles r\u00e9cents et leur code correspondants.</p>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#lectures-par-thematiques","title":"Lectures par th\u00e9matiques","text":"<ul> <li>Un article du blog towards data science vulgaris\u00e9 sur les param\u00e8tres et hyper-param\u00e8tres des r\u00e9seaux de neurones</li> <li>Si vous \u00eates int\u00e9ress\u00e9 par le Natural Language Processing et que vous souhaitez approfondir le sujet de mani\u00e8re d\u00e9taill\u00e9e, je vous sugg\u00e8re de regarder la s\u00e9rie de vid\u00e9os du cours d\u00e9di\u00e9 de Standford CS224N</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#mathematiques-pour-le-deep-learning","title":"Math\u00e9matiques pour le deep learning","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#algebre-lineaire_1","title":"Alg\u00e8bre lin\u00e9aire","text":"<p>L'alg\u00e9bre lin\u00e9aire est un domaine des math\u00e9matiques dont vous aurez particuli\u00e8rement besoin durant ce cours pour comprendre les notions de vecteurs, matrices, tenseurs et leurs op\u00e9rations associ\u00e9es.</p> <ul> <li>Cette s\u00e9rie de cours vid\u00e9os de la chaine 3Blue1Brown vous aidera \u00e0 apprendre les bases de l'alg\u00e8bre lin\u00e9aire, en particulier les notions de vecteurs, d'espaces vectoriels et de matrices. Je vous conseille de vous concentrer sur les videos 1,2,3,4,9,10 et 11</li> </ul>"},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#tutoriels-exercices","title":"Tutoriels &amp; Exercices","text":""},{"location":"ressources%20additionnelles/elements_cours/ressources_datascience_IA/#deep-learning_1","title":"Deep Learning","text":"<ul> <li> <p>La section tutoriel de Tensorflow est compl\u00e8te et d\u00e9taill\u00e9e. Commencez par la section pour les d\u00e9butants. Vous pourrez ex\u00e9cuter le code propos\u00e9 dans Colab, le notebook propos\u00e9 par Google</p> </li> <li> <p>La section tutorial de PyTorch contient des exercices et des applications classique du deep learning. Je vous recommande en particulier le  tutoriel deep learning 60min blitz pour apprendre \u00e0 manipuler le framework</p> </li> </ul>"}]}